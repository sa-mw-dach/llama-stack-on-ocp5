{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ecd807-fb1c-41eb-a948-365e57396d90",
   "metadata": {},
   "source": [
    "# Level 4: Agentic & MCP (Medium Difficulty)\n",
    "\n",
    "This tutorial is aimed at those already familiar with basic Agentic workflows. It is meant to showcase  **sequential tool calls** or **conditional logic** within the context of an agentic workflow.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will be connecting to a llama-stack instance, building an agent with various tools available to it, and inferencing against the agent.\n",
    "\n",
    "## Pre-Requisites\n",
    "\n",
    "Before starting, ensure you have the following:\n",
    "- Access to an openshift cluster with A deployment of the [openshift MCP server](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/mcp-servers/openshift) (see the [deployment manifests](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/kubernetes/mcp-servers/openshift-mcp) for assistance with this).\n",
    "- User variables configured (see section `Setting your ENV variables` below).\n",
    "- A Tavily API key is required. You can register for one at https://tavily.com/home.\n",
    "\n",
    "## General Setup\n",
    "\n",
    "These steps will be the same for all 3 queries, with the exception of inputing the Tavily API key - this will only be used for query 2, and so could be ommitted if one only wants to run demos 1 or 3.\n",
    "\n",
    "### Setting your ENV variables:\n",
    "\n",
    "As mentioned above, for this demo there are a few ENV variables that need to set:\n",
    "- `REMOTE` (boolean): dictates if you are using a remote llama-stack instance.\n",
    "- `REMOTE_BASE_URL` (string): the URL for your llama-stack instance if using remote connection.\n",
    "- `TAVILY_SEARCH_API_KEY` (string): your API key for tavily search. One can get one by going to: https://tavily.com/home.\n",
    "- `REMOTE_OCP_MCP_URL` (string): the URL for your Openshift MCP server. If the client does not find the tool registered to the llama-stack instance, it will use this URL to register the Openshift tool (used in demos 1 and 3).\n",
    "- `USE_PROMPT_CHAINING` (boolean): dictates if the prompt should be formatted as 3 separate prompts to isolate the steps. This is an option because a single inference call is able to do the search and draft the email, but by destructuring this into sub-steps where the LLM can focus on a single task at a time can theoretically increase performance. Additionally while this task can be accomplished from a single prompt, other more complex questions may not be doable in this way. This prompt-chaining example is meant to demonstrate how one might do this.\n",
    "\n",
    "### Installing dependencies\n",
    "\n",
    "This code requires `llama-stack` and the `llama-stack-client`, both at version `0.1.9`. Lets begin by installing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-stack-client==0.1.9 llama-stack==0.1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee3cb2",
   "metadata": {},
   "source": [
    "### Configuring logging\n",
    "\n",
    "Now that we have our dependencies, lets setup logging for the application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "if not logger.hasHandlers():  \n",
    "    logger.setLevel(logging.INFO)\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681412e1",
   "metadata": {},
   "source": [
    "### Connecting to llama-stack server\n",
    "\n",
    "For the llama-stack instance, you can either run it locally or connect to a remote llama-stack instance.\n",
    "\n",
    "#### Remote llama-stack\n",
    "\n",
    "- For remote, be sure to set `remote` to `True` and populate the `remote_llama_stack_endpoint` variable with your llama-stack remote.\n",
    "- [Remote Setup Guide](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/kubernetes)\n",
    "\n",
    "#### Local llama-stack\n",
    "- For local, be sure to set `remote` to `False` and validate the `local_llama_stack_endpoint` variable. It is based off of the default llama-stack port which is `8321` but is configurable with your deployment of llama-stack.\n",
    "- [Local Setup Guide](https://github.com/redhat-et/agent-frameworks/tree/main/prototype/frameworks/llamastack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa38ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "remote = os.getenv(\"REMOTE\", True) # Use the `remote` variable to switching between a local development environment and a remote kubernetes cluster.\n",
    "model=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "if remote:\n",
    "    base_url = os.getenv(\"REMOTE_BASE_URL\")\n",
    "else:\n",
    "    base_url = \"http://localhost:8321\"\n",
    "\n",
    "tavily_search_api_key = os.getenv(\"TAVILY_SEARCH_API_KEY\") # Replace with your Tavily API key (required for demo 2)\n",
    "\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data={\n",
    "        \"tavily_search_api_key\": tavily_search_api_key # This is required for demo 2\n",
    "    }\n",
    ")\n",
    "    \n",
    "logger.info(f\"Connected to Llama Stack server @ {base_url} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66044170",
   "metadata": {},
   "source": [
    "### Validate tools are available in our llama-stack instance\n",
    "\n",
    "When an instance of llama-stack is redeployed your tools need to re-registered. Also if a tool is already registered with a llama-stack instance, if you try to register one with the same `toolgroup_id`, llama-stack will throw you an error.\n",
    "\n",
    "For this reason it is recommended to include some code to validate your tools and toolgroups. This is where the `mcp_url` comes into play. The following code will check that both the `builtin::websearch` and the `mcp::openshift` tools are registered as tools, but if the `mcp::openshift` tool is not listed there, it will attempt to register it using the mcp url.\n",
    "\n",
    "If you are running the MCP server from source, the default value for this is: `http://localhost:8000/sse`.\n",
    "\n",
    "If you are running the MCP server from a container, the default value for this is: `http://host.containers.internal:8000/sse`.\n",
    "\n",
    "Make sure to pass the corresponding MCP URL for the server you are trying to register/validate tools for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cedaf-522b-4251-886a-d8aa7b9fcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_url = os.getenv(\"REMOTE_OCP_MCP_URL\") # Optional: enter your MCP server url here\n",
    "\n",
    "registered_tools = client.tools.list()\n",
    "registered_toolgroups = [t.toolgroup_id for t in registered_tools]\n",
    "if  \"builtin::websearch\" not in registered_toolgroups: # Required for demo 2\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"builtin::websearch\",\n",
    "        provider_id=\"tavily-search\",\n",
    "        args={\"max_results\": 10},\n",
    "    )\n",
    "    \n",
    "if \"mcp::openshift\" not in registered_toolgroups: # required for demos 1 and 3\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"mcp::openshift\",\n",
    "        provider_id=\"model-context-protocol\",\n",
    "        mcp_endpoint={\"uri\":mcp_url},\n",
    "    )\n",
    "logger.info(f\"Your Llama Stack server is already registered with the following tool groups @ {set(registered_toolgroups)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5cbe2",
   "metadata": {},
   "source": [
    "## Query 1: (Agentic) `Use OpenShift MCP Server to create a new pod`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf70ace-b704-4379-aa88-3c793cc4f959",
   "metadata": {},
   "source": [
    "### System Prompts for different models\n",
    "\n",
    "**Note:** If you have multiple models configured with your Llama Stack server, you can choose which one to run your queries against. When switching to a different model, you may need to adjust the system prompt to align with that model’s expected behavior. Many models provide recommended system prompts for optimal and reliable outputs—these are typically documented on their respective websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374328a3-8c4d-4eb0-9c9d-73e40a9e74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a system prompt we have come up with which works well for this query\n",
    "\n",
    "granite_model=\"ibm-granite/granite-3.2-8b-instruct\"\n",
    "llama_model=\"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "sys_prompt1= \"\"\"You are a helpful assistant. Use tools to answer. When you use a tool always respond with a summary of the result.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b46bee8b-a46c-4b97-8273-dda75237d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minference> \u001b[0m\u001b[33m<\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_\u001b[0m\u001b[33mcall\u001b[0m\u001b[33m>\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:pods_run Args:{'image': 'docker.io/hello-world', 'name': 'hello-world', 'namespace': 'llama-serve'}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:pods_run Response:{\"type\":\"text\",\"text\":\"# The following resources (YAML) have been created or updated successfully\\n- apiVersion: v1\\n  kind: Pod\\n  metadata:\\n    annotations:\\n      openshift.io/scc: restricted-v2\\n      seccomp.security.alpha.kubernetes.io/pod: runtime/default\\n    creationTimestamp: \\\"2025-04-11T22:44:30Z\\\"\\n    labels:\\n      app.kubernetes.io/component: hello-world\\n      app.kubernetes.io/managed-by: kubernetes-mcp-server\\n      app.kubernetes.io/name: hello-world\\n      app.kubernetes.io/part-of: kubernetes-mcp-server-run-sandbox\\n    name: hello-world\\n    namespace: llama-serve\\n    resourceVersion: \\\"772876693\\\"\\n    uid: 30f17cc2-f0b2-48e1-9262-cad6051149ea\\n  spec:\\n    containers:\\n    - image: docker.io/hello-world\\n      imagePullPolicy: Always\\n      name: hello-world\\n      resources: {}\\n      securityContext:\\n        allowPrivilegeEscalation: false\\n        capabilities:\\n          drop:\\n          - ALL\\n        runAsNonRoot: true\\n        runAsUser: 1001550000\\n      terminationMessagePath: /dev/termination-log\\n      terminationMessagePolicy: File\\n      volumeMounts:\\n      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\\n        name: kube-api-access-krxw8\\n        readOnly: true\\n    dnsPolicy: ClusterFirst\\n    enableServiceLinks: true\\n    imagePullSecrets:\\n    - name: default-dockercfg-prvxh\\n    preemptionPolicy: PreemptLowerPriority\\n    priority: 0\\n    restartPolicy: Always\\n    schedulerName: default-scheduler\\n    securityContext:\\n      fsGroup: 1001550000\\n      seLinuxOptions:\\n        level: s0:c39,c34\\n      seccompProfile:\\n        type: RuntimeDefault\\n    serviceAccount: default\\n    serviceAccountName: default\\n    terminationGracePeriodSeconds: 30\\n    tolerations:\\n    - effect: NoExecute\\n      key: node.kubernetes.io/not-ready\\n      operator: Exists\\n      tolerationSeconds: 300\\n    - effect: NoExecute\\n      key: node.kubernetes.io/unreachable\\n      operator: Exists\\n      tolerationSeconds: 300\\n    volumes:\\n    - name: kube-api-access-krxw8\\n      projected:\\n        defaultMode: 420\\n        sources:\\n        - serviceAccountToken:\\n            expirationSeconds: 3607\\n            path: token\\n        - configMap:\\n            items:\\n            - key: ca.crt\\n              path: ca.crt\\n            name: kube-root-ca.crt\\n        - downwardAPI:\\n            items:\\n            - fieldRef:\\n                apiVersion: v1\\n                fieldPath: metadata.namespace\\n              path: namespace\\n        - configMap:\\n            items:\\n            - key: service-ca.crt\\n              path: service-ca.crt\\n            name: openshift-service-ca.crt\\n  status:\\n    phase: Pending\\n    qosClass: BestEffort\\n\",\"annotations\":null}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33mThe\u001b[0m\u001b[33m '\u001b[0m\u001b[33mhello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m'\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m has\u001b[0m\u001b[33m been\u001b[0m\u001b[33m successfully\u001b[0m\u001b[33m created\u001b[0m\u001b[33m in\u001b[0m\u001b[33m the\u001b[0m\u001b[33m '\u001b[0m\u001b[33mll\u001b[0m\u001b[33mama\u001b[0m\u001b[33m-\u001b[0m\u001b[33mserve\u001b[0m\u001b[33m'\u001b[0m\u001b[33m namespace\u001b[0m\u001b[33m using\u001b[0m\u001b[33m the\u001b[0m\u001b[33m image\u001b[0m\u001b[33m '\u001b[0m\u001b[33mdocker\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mhello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m'.\u001b[0m\u001b[33m Here\u001b[0m\u001b[33m is\u001b[0m\u001b[33m the\u001b[0m\u001b[33m YAML\u001b[0m\u001b[33m representation\u001b[0m\u001b[33m of\u001b[0m\u001b[33m the\u001b[0m\u001b[33m created\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m```\u001b[0m\u001b[33myaml\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m#\u001b[0m\u001b[33m The\u001b[0m\u001b[33m following\u001b[0m\u001b[33m resources\u001b[0m\u001b[33m (\u001b[0m\u001b[33mYAML\u001b[0m\u001b[33m)\u001b[0m\u001b[33m have\u001b[0m\u001b[33m been\u001b[0m\u001b[33m created\u001b[0m\u001b[33m or\u001b[0m\u001b[33m updated\u001b[0m\u001b[33m successfully\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mapiVersion\u001b[0m\u001b[33m:\u001b[0m\u001b[33m v\u001b[0m\u001b[33m1\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mkind\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Pod\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mmetadata\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m annotations\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m open\u001b[0m\u001b[33mshift\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mscc\u001b[0m\u001b[33m:\u001b[0m\u001b[33m restricted\u001b[0m\u001b[33m-\u001b[0m\u001b[33mv\u001b[0m\u001b[33m2\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m sec\u001b[0m\u001b[33mcomp\u001b[0m\u001b[33m.\u001b[0m\u001b[33msecurity\u001b[0m\u001b[33m.\u001b[0m\u001b[33malpha\u001b[0m\u001b[33m.\u001b[0m\u001b[33mkubernetes\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mpod\u001b[0m\u001b[33m:\u001b[0m\u001b[33m runtime\u001b[0m\u001b[33m/\u001b[0m\u001b[33mdefault\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m creation\u001b[0m\u001b[33mTimestamp\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \"\u001b[0m\u001b[33m2\u001b[0m\u001b[33m0\u001b[0m\u001b[33m2\u001b[0m\u001b[33m5\u001b[0m\u001b[33m-\u001b[0m\u001b[33m0\u001b[0m\u001b[33m4\u001b[0m\u001b[33m-\u001b[0m\u001b[33m1\u001b[0m\u001b[33m1\u001b[0m\u001b[33mT\u001b[0m\u001b[33m2\u001b[0m\u001b[33m2\u001b[0m\u001b[33m:\u001b[0m\u001b[33m4\u001b[0m\u001b[33m4\u001b[0m\u001b[33m:\u001b[0m\u001b[33m3\u001b[0m\u001b[33m0\u001b[0m\u001b[33mZ\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m labels\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m app\u001b[0m\u001b[33m.\u001b[0m\u001b[33mkubernetes\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mcomponent\u001b[0m\u001b[33m:\u001b[0m\u001b[33m hello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m app\u001b[0m\u001b[33m.\u001b[0m\u001b[33mkubernetes\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mmanaged\u001b[0m\u001b[33m-\u001b[0m\u001b[33mby\u001b[0m\u001b[33m:\u001b[0m\u001b[33m kubernetes\u001b[0m\u001b[33m-\u001b[0m\u001b[33mm\u001b[0m\u001b[33mcp\u001b[0m\u001b[33m-\u001b[0m\u001b[33mserver\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m app\u001b[0m\u001b[33m.\u001b[0m\u001b[33mkubernetes\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mname\u001b[0m\u001b[33m:\u001b[0m\u001b[33m hello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m app\u001b[0m\u001b[33m.\u001b[0m\u001b[33mkubernetes\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mpart\u001b[0m\u001b[33m-\u001b[0m\u001b[33mof\u001b[0m\u001b[33m:\u001b[0m\u001b[33m kubernetes\u001b[0m\u001b[33m-\u001b[0m\u001b[33mm\u001b[0m\u001b[33mcp\u001b[0m\u001b[33m-\u001b[0m\u001b[33mserver\u001b[0m\u001b[33m-\u001b[0m\u001b[33mrun\u001b[0m\u001b[33m-\u001b[0m\u001b[33msandbox\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m hello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m namespace\u001b[0m\u001b[33m:\u001b[0m\u001b[33m ll\u001b[0m\u001b[33mama\u001b[0m\u001b[33m-\u001b[0m\u001b[33mserve\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m resource\u001b[0m\u001b[33mVersion\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \"\u001b[0m\u001b[33m7\u001b[0m\u001b[33m7\u001b[0m\u001b[33m2\u001b[0m\u001b[33m8\u001b[0m\u001b[33m7\u001b[0m\u001b[33m6\u001b[0m\u001b[33m6\u001b[0m\u001b[33m9\u001b[0m\u001b[33m3\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m uid\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m3\u001b[0m\u001b[33m0\u001b[0m\u001b[33mf\u001b[0m\u001b[33m1\u001b[0m\u001b[33m7\u001b[0m\u001b[33mcc\u001b[0m\u001b[33m2\u001b[0m\u001b[33m-\u001b[0m\u001b[33mf\u001b[0m\u001b[33m0\u001b[0m\u001b[33mb\u001b[0m\u001b[33m2\u001b[0m\u001b[33m-\u001b[0m\u001b[33m4\u001b[0m\u001b[33m8\u001b[0m\u001b[33me\u001b[0m\u001b[33m1\u001b[0m\u001b[33m-\u001b[0m\u001b[33m9\u001b[0m\u001b[33m2\u001b[0m\u001b[33m6\u001b[0m\u001b[33m2\u001b[0m\u001b[33m-\u001b[0m\u001b[33mcad\u001b[0m\u001b[33m6\u001b[0m\u001b[33m0\u001b[0m\u001b[33m5\u001b[0m\u001b[33m1\u001b[0m\u001b[33m1\u001b[0m\u001b[33m4\u001b[0m\u001b[33m9\u001b[0m\u001b[33mea\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mspec\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m containers\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m -\u001b[0m\u001b[33m image\u001b[0m\u001b[33m:\u001b[0m\u001b[33m docker\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mhello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m image\u001b[0m\u001b[33mPull\u001b[0m\u001b[33mPolicy\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Always\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m hello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m resources\u001b[0m\u001b[33m:\u001b[0m\u001b[33m {}\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m security\u001b[0m\u001b[33mContext\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m allow\u001b[0m\u001b[33mPrivilege\u001b[0m\u001b[33mE\u001b[0m\u001b[33mscal\u001b[0m\u001b[33mation\u001b[0m\u001b[33m:\u001b[0m\u001b[33m false\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m capabilities\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "       \u001b[0m\u001b[33m drop\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "       \u001b[0m\u001b[33m -\u001b[0m\u001b[33m ALL\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m run\u001b[0m\u001b[33mAs\u001b[0m\u001b[33mNon\u001b[0m\u001b[33mRoot\u001b[0m\u001b[33m:\u001b[0m\u001b[33m true\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m run\u001b[0m\u001b[33mAs\u001b[0m\u001b[33mUser\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m1\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m1\u001b[0m\u001b[33m5\u001b[0m\u001b[33m5\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m termination\u001b[0m\u001b[33mMessage\u001b[0m\u001b[33mPath\u001b[0m\u001b[33m:\u001b[0m\u001b[33m /\u001b[0m\u001b[33mdev\u001b[0m\u001b[33m/\u001b[0m\u001b[33mtermination\u001b[0m\u001b[33m-\u001b[0m\u001b[33mlog\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m termination\u001b[0m\u001b[33mMessage\u001b[0m\u001b[33mPolicy\u001b[0m\u001b[33m:\u001b[0m\u001b[33m File\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m volume\u001b[0m\u001b[33mMount\u001b[0m\u001b[33ms\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m -\u001b[0m\u001b[33m mount\u001b[0m\u001b[33mPath\u001b[0m\u001b[33m:\u001b[0m\u001b[33m /\u001b[0m\u001b[33mvar\u001b[0m\u001b[33m/\u001b[0m\u001b[33mrun\u001b[0m\u001b[33m/\u001b[0m\u001b[33msecrets\u001b[0m\u001b[33m/\u001b[0m\u001b[33mkubernetes\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mservice\u001b[0m\u001b[33maccount\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m kube\u001b[0m\u001b[33m-\u001b[0m\u001b[33mapi\u001b[0m\u001b[33m-\u001b[0m\u001b[33maccess\u001b[0m\u001b[33m-\u001b[0m\u001b[33mk\u001b[0m\u001b[33mrx\u001b[0m\u001b[33mw\u001b[0m\u001b[33m8\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m readOnly\u001b[0m\u001b[33m:\u001b[0m\u001b[33m true\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m dns\u001b[0m\u001b[33mPolicy\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Cluster\u001b[0m\u001b[33mFirst\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m enable\u001b[0m\u001b[33mService\u001b[0m\u001b[33mLinks\u001b[0m\u001b[33m:\u001b[0m\u001b[33m true\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m image\u001b[0m\u001b[33mPull\u001b[0m\u001b[33mSecrets\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m -\u001b[0m\u001b[33m name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m default\u001b[0m\u001b[33m-\u001b[0m\u001b[33mdocker\u001b[0m\u001b[33mcfg\u001b[0m\u001b[33m-\u001b[0m\u001b[33mpr\u001b[0m\u001b[33mvx\u001b[0m\u001b[33mh\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m pre\u001b[0m\u001b[33memption\u001b[0m\u001b[33mPolicy\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Pre\u001b[0m\u001b[33mempt\u001b[0m\u001b[33mLower\u001b[0m\u001b[33mPriority\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m priority\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m0\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m restart\u001b[0m\u001b[33mPolicy\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Always\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m scheduler\u001b[0m\u001b[33mName\u001b[0m\u001b[33m:\u001b[0m\u001b[33m default\u001b[0m\u001b[33m-\u001b[0m\u001b[33mscheduler\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m security\u001b[0m\u001b[33mContext\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m fs\u001b[0m\u001b[33mGroup\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m1\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m1\u001b[0m\u001b[33m5\u001b[0m\u001b[33m5\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m se\u001b[0m\u001b[33mLinux\u001b[0m\u001b[33mOptions\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m level\u001b[0m\u001b[33m:\u001b[0m\u001b[33m s\u001b[0m\u001b[33m0\u001b[0m\u001b[33m:\u001b[0m\u001b[33mc\u001b[0m\u001b[33m3\u001b[0m\u001b[33m9\u001b[0m\u001b[33m,\u001b[0m\u001b[33mc\u001b[0m\u001b[33m3\u001b[0m\u001b[33m4\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m sec\u001b[0m\u001b[33mcomp\u001b[0m\u001b[33mProfile\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m type\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Runtime\u001b[0m\u001b[33mDefault\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m service\u001b[0m\u001b[33mAccount\u001b[0m\u001b[33m:\u001b[0m\u001b[33m default\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m service\u001b[0m\u001b[33mAccountName\u001b[0m\u001b[33m:\u001b[0m\u001b[33m default\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m termination\u001b[0m\u001b[33mGrace\u001b[0m\u001b[33mPeriod\u001b[0m\u001b[33mSeconds\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m3\u001b[0m\u001b[33m0\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m t\u001b[0m\u001b[33moler\u001b[0m\u001b[33mations\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m -\u001b[0m\u001b[33m effect\u001b[0m\u001b[33m:\u001b[0m\u001b[33m No\u001b[0m\u001b[33mExecute\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m key\u001b[0m\u001b[33m:\u001b[0m\u001b[33m node\u001b[0m\u001b[33m.\u001b[0m\u001b[33mkubernetes\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33mnot\u001b[0m\u001b[33m-\u001b[0m\u001b[33mready\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m operator\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ex\u001b[0m\u001b[33mists\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m tol\u001b[0m\u001b[33meration\u001b[0m\u001b[33mSeconds\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m3\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m -\u001b[0m\u001b[33m effect\u001b[0m\u001b[33m:\u001b[0m\u001b[33m No\u001b[0m\u001b[33mExecute\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m key\u001b[0m\u001b[33m:\u001b[0m\u001b[33m node\u001b[0m\u001b[33m.\u001b[0m\u001b[33mkubernetes\u001b[0m\u001b[33m.\u001b[0m\u001b[33mio\u001b[0m\u001b[33m/\u001b[0m\u001b[33munreachable\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m operator\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Ex\u001b[0m\u001b[33mists\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m tol\u001b[0m\u001b[33meration\u001b[0m\u001b[33mSeconds\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m3\u001b[0m\u001b[33m0\u001b[0m\u001b[33m0\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m volumes\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m -\u001b[0m\u001b[33m name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m kube\u001b[0m\u001b[33m-\u001b[0m\u001b[33mapi\u001b[0m\u001b[33m-\u001b[0m\u001b[33maccess\u001b[0m\u001b[33m-\u001b[0m\u001b[33mk\u001b[0m\u001b[33mrx\u001b[0m\u001b[33mw\u001b[0m\u001b[33m8\u001b[0m\u001b[33m\n",
      "   \u001b[0m\u001b[33m projected\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m default\u001b[0m\u001b[33mMode\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m4\u001b[0m\u001b[33m2\u001b[0m\u001b[33m0\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m sources\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m -\u001b[0m\u001b[33m service\u001b[0m\u001b[33mAccount\u001b[0m\u001b[33mToken\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m expiration\u001b[0m\u001b[33mSeconds\u001b[0m\u001b[33m:\u001b[0m\u001b[33m \u001b[0m\u001b[33m3\u001b[0m\u001b[33m6\u001b[0m\u001b[33m0\u001b[0m\u001b[33m7\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m path\u001b[0m\u001b[33m:\u001b[0m\u001b[33m token\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m -\u001b[0m\u001b[33m config\u001b[0m\u001b[33mMap\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m items\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m -\u001b[0m\u001b[33m key\u001b[0m\u001b[33m:\u001b[0m\u001b[33m ca\u001b[0m\u001b[33m.\u001b[0m\u001b[33mcrt\u001b[0m\u001b[33m\n",
      "           \u001b[0m\u001b[33m path\u001b[0m\u001b[33m:\u001b[0m\u001b[33m ca\u001b[0m\u001b[33m.\u001b[0m\u001b[33mcrt\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m kube\u001b[0m\u001b[33m-\u001b[0m\u001b[33mroot\u001b[0m\u001b[33m-\u001b[0m\u001b[33mca\u001b[0m\u001b[33m.\u001b[0m\u001b[33mcrt\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m -\u001b[0m\u001b[33m down\u001b[0m\u001b[33mward\u001b[0m\u001b[33mAPI\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m items\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m -\u001b[0m\u001b[33m field\u001b[0m\u001b[33mRef\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "             \u001b[0m\u001b[33m apiVersion\u001b[0m\u001b[33m:\u001b[0m\u001b[33m v\u001b[0m\u001b[33m1\u001b[0m\u001b[33m\n",
      "             \u001b[0m\u001b[33m field\u001b[0m\u001b[33mPath\u001b[0m\u001b[33m:\u001b[0m\u001b[33m metadata\u001b[0m\u001b[33m.\u001b[0m\u001b[33mnamespace\u001b[0m\u001b[33m\n",
      "           \u001b[0m\u001b[33m path\u001b[0m\u001b[33m:\u001b[0m\u001b[33m namespace\u001b[0m\u001b[33m\n",
      "     \u001b[0m\u001b[33m -\u001b[0m\u001b[33m config\u001b[0m\u001b[33mMap\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m items\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m -\u001b[0m\u001b[33m key\u001b[0m\u001b[33m:\u001b[0m\u001b[33m service\u001b[0m\u001b[33m-\u001b[0m\u001b[33mca\u001b[0m\u001b[33m.\u001b[0m\u001b[33mcrt\u001b[0m\u001b[33m\n",
      "           \u001b[0m\u001b[33m path\u001b[0m\u001b[33m:\u001b[0m\u001b[33m service\u001b[0m\u001b[33m-\u001b[0m\u001b[33mca\u001b[0m\u001b[33m.\u001b[0m\u001b[33mcrt\u001b[0m\u001b[33m\n",
      "         \u001b[0m\u001b[33m name\u001b[0m\u001b[33m:\u001b[0m\u001b[33m open\u001b[0m\u001b[33mshift\u001b[0m\u001b[33m-\u001b[0m\u001b[33mservice\u001b[0m\u001b[33m-\u001b[0m\u001b[33mca\u001b[0m\u001b[33m.\u001b[0m\u001b[33mcrt\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mstatus\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m phase\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Pending\u001b[0m\u001b[33m\n",
      " \u001b[0m\u001b[33m q\u001b[0m\u001b[33mos\u001b[0m\u001b[33mClass\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Best\u001b[0m\u001b[33mEff\u001b[0m\u001b[33mort\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m```\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mThe\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m's\u001b[0m\u001b[33m status\u001b[0m\u001b[33m is\u001b[0m\u001b[33m currently\u001b[0m\u001b[33m '\u001b[0m\u001b[33mPending\u001b[0m\u001b[33m',\u001b[0m\u001b[33m which\u001b[0m\u001b[33m means\u001b[0m\u001b[33m it\u001b[0m\u001b[33m is\u001b[0m\u001b[33m waiting\u001b[0m\u001b[33m for\u001b[0m\u001b[33m a\u001b[0m\u001b[33m node\u001b[0m\u001b[33m to\u001b[0m\u001b[33m become\u001b[0m\u001b[33m available\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Once\u001b[0m\u001b[33m a\u001b[0m\u001b[33m node\u001b[0m\u001b[33m is\u001b[0m\u001b[33m available\u001b[0m\u001b[33m,\u001b[0m\u001b[33m the\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m will\u001b[0m\u001b[33m be\u001b[0m\u001b[33m scheduled\u001b[0m\u001b[33m and\u001b[0m\u001b[33m its\u001b[0m\u001b[33m status\u001b[0m\u001b[33m will\u001b[0m\u001b[33m change\u001b[0m\u001b[33m to\u001b[0m\u001b[33m '\u001b[0m\u001b[33mRunning\u001b[0m\u001b[33m'.\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "from llama_stack_client import Agent\n",
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=granite_model, # replace this with your choice of model\n",
    "    instructions = sys_prompt1 , # update system prompt based on the model you are using\n",
    "    tools=[\"mcp::openshift\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params={\"max_tokens\":4096}\n",
    ")\n",
    "\n",
    "user_prompts = [\"Create a new pod called 'hello-world' using the image docker.io/hello-world in the llama-serve namespace.\"]\n",
    "session_id = agent.create_session(session_name=\"OCP_demo\")\n",
    "\n",
    "for prompt in user_prompts:\n",
    "    turn_response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=True,\n",
    "    )\n",
    "    for log in EventLogger().log(turn_response):\n",
    "        log.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e857dcc-6e78-42b7-96c3-4a3d32d59b4d",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Lets step through the output to further understands whats happening in this Agentic demo.\n",
    "\n",
    "1. First the LLM sends off a tool call to the pods_run tool configured with the OpenShift MCP server, to run the pod with the requested docker image in the OpenShift cluster.\n",
    "2. The tool successfully executes and creates the pod.\n",
    "3. The LLM recieves the response from the tool call, results of the pod manifest created, along with the original query.\n",
    "4. Finally, this context gets passed back to the LLM for the final inference. The inference result starts by responding to my initial question with some background, and then finally providing details about the pod specifications and configurations created as well mentionining that the pod might be in pending state indicating that it might take few minutes to successfully complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9830e45-5633-4eb3-9270-643a27e24f2a",
   "metadata": {},
   "source": [
    "## Query 2: (Agentic): `Email my team about the latest announcements from OpenShift`\n",
    "\n",
    "Previously, we instantiated our llama-stack client with our tavily search API key, and connected to our instance of that llama-stack client, before ensuring our required tools and toolgroups are registered to that llamastack instance.\n",
    "\n",
    "Now we can create our agent, and start our agent sessions. As described above, we will need to decide if we want to use prompt-chaining or not. While its not required for this medium complexity query, as the model is good enough to do both the tool call and inference in one step, this may not be the case for other more complex queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd82e55-17df-4979-86ef-22e35a186c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a system prompt we have come up with which works well for this query\n",
    "sys_prompt2=\"\"\"You are a helpful AI assistant, responsible for helping me find and communicate information back to my team.\n",
    "    You have access to a number of tools.\n",
    "    Whenever a tool is called, be sure return the Response in a friendly and helpful tone.\n",
    "    When you are asked to search the web you must use a tool.\n",
    "    When signing off on emails, please be sure to include: - Sent from my llama-stack agent in the signature\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55883a-6887-43dd-9498-5333a51799e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minference> \u001b[0m\u001b[97m\u001b[0m\n",
      ",\u001b[32mtool_execution> Tool:brave_search Args:{'query': 'latest Red Hat OpenShift version'}\u001b[0m\n",
      ",\u001b[32mtool_execution> Tool:brave_search Response:{\"query\": \"latest Red Hat OpenShift version\", \"top_k\": [{\"title\": \"Red Hat Enhances Security and Virtualization Experience with Latest ...\", \"url\": \"https://www.redhat.com/en/about/press-releases/red-hat-enhances-security-and-virtualization-experience-latest-version-red-hat-openshift\", \"content\": \"Red Hat, Inc., the world's leading provider of open source solutions, today announced the general availability of Red Hat OpenShift 4.18, the latest version of the industry\\u2019s leading hybrid cloud application platform powered by Kubernetes. Red Hat OpenShift 4.18 introduces new features and capabilities designed to streamline operations and security across IT environments and deliver greater consistency to all applications, from cloud-native and AI-enabled to virtualized and traditional. Additionally, for users looking for virtualization in the public cloud, Red Hat OpenShift Virtualization is now available on Oracle Cloud Infrastructure as a technology preview. Red Hat OpenShift 4.18 is now available, introducing new features and capabilities designed to streamline operations and security across IT environments and deliver greater consistency to all applications, from cloud-native and AI-enabled to virtualized and traditional.\", \"score\": 0.9296516, \"raw_content\": null}, {\"title\": \"Red Hat OpenShift 4.17: What you need to know\", \"url\": \"https://www.redhat.com/en/blog/what-you-need-to-know-red-hat-openshift-417\", \"content\": \"Based on\\u00a0Kubernetes 1.30 and\\u00a0CRI-O 1.30,\\u00a0 OpenShift 4.17 features expanded control plane options, increased flexibility for virtualization and networking, new capabilities to leverage generative AI, and continued investment in\\u00a0Red Hat OpenShift Platform Plus. Red Hat OpenShift Platform Plus (OPP) is an expanded version of Red Hat OpenShift that provides a comprehensive hybrid cloud platform with built-in security features for enterprises to build, deploy, run, manage, and automate applications at scale. For\\u00a0Red Hat OpenShift Data Foundation (ODF), we\\u2019re promoting to general availability the use of customer-managed ODF with\\u00a0Red Hat OpenShift Service on AWS with hosted control planes clusters in ODF 4.17.z. Ju Lim works on the core Red Hat OpenShift Container Platform for hybrid and multi-cloud environments to enable customers to run Red Hat OpenShift anywhere.\", \"score\": 0.8232293, \"raw_content\": null}, {\"title\": \"What's new in Red Hat OpenShift\", \"url\": \"https://www.redhat.com/en/whats-new-red-hat-openshift\", \"content\": \"What's new in Red Hat OpenShift All Red Hat Red Hat AI portfolioTune small language models and develop and deploy solutions across the hybrid cloud with our line of AI products and services. Red Hat OpenShift AI Artificial intelligenceBuild, deploy, and monitor AI models and apps with Red Hat's open source platforms. Red Hat OpenShift Service on AWS Buy onlineBuy select products and services in the Red Hat Store. Containers, Kubernetes and Red Hat OpenShift Technical Overview (No cost) Why build a Red Hat cloud? Explore Red Hat All Red Hat products Red Hat resources What's new in Red Hat OpenShift Red Hat OpenShift Red Hat Ansible Automation Platform About Red Hat About Red Hat Contact Red Hat\", \"score\": 0.48396602, \"raw_content\": null}, {\"title\": \"Red Hat OpenShift Container Platform Life Cycle Policy\", \"url\": \"https://access.redhat.com/support/policy/updates/openshift/\", \"content\": \"Extended Update Support - Long Life Add-on - Additional Term 1 enables customers to remain with the same minor release of Red Hat OpenShift for a total 24 months, allowing for stable production environments for mission-critical applications. Extended Update Support - Long Life Add-on - Additional Term 1 is provided with all Premium subscriptions for x86-64 versions of Red Hat OpenShift Kubernetes Engine, Red Hat OpenShift Container Platform, and Red Hat OpenShift Platform Plus. The combination of Extended Update Support - Long Life Add-On - Additional Term 1 and Extended Update Support Long Life Add-on - Additional Term 2 (footnote [13]) enables customers to remain with the same minor release of Red Hat OpenShift for a total of 36 months, allowing for stable production environments for mission-critical applications.\", \"score\": 0.46935064, \"raw_content\": null}, {\"title\": \"Download Red Hat Openshift - Red Hat Developer\", \"url\": \"https://developers.redhat.com/products/openshift/download\", \"content\": \"Red Hat OpenShift The trial includes membership in the Red Hat Developer program, which gives you access to evaluation software from Red Hat, tutorials, labs, cheat sheets, e-books, and more. Install Red Hat OpenShift on any supported public cloud providers: Amazon Web services, IBM, and Microsoft Azure. Create a minimal cluster on your desktop or laptop for local development and testing with Red Hat OpenShift Local. Start, stop, and deploy to Red Hat server and runtime products like Wildfly, JBoss EAP (Enterprise Application Platform), Minishift, CDK (Container Development Kit). The CLI that helps developers iterate their code on Red Hat OpenShift and Kubernetes. Red Hat OpenShift Serverless Operator Red Hat OpenShift Service Mesh Operator RED HAT DEVELOPER\", \"score\": 0.39201146, \"raw_content\": null}]}\u001b[0m\n",
      ",\u001b[33minference> \u001b[0m\u001b[33mThe\u001b[0m\u001b[33m latest\u001b[0m\u001b[33m version\u001b[0m\u001b[33m of\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m is\u001b[0m\u001b[33m \u001b[0m\u001b[33m4\u001b[0m\u001b[33m.\u001b[0m\u001b[33m18\u001b[0m\u001b[33m.\u001b[0m\u001b[33m This\u001b[0m\u001b[33m version\u001b[0m\u001b[33m introduces\u001b[0m\u001b[33m new\u001b[0m\u001b[33m features\u001b[0m\u001b[33m and\u001b[0m\u001b[33m capabilities\u001b[0m\u001b[33m designed\u001b[0m\u001b[33m to\u001b[0m\u001b[33m streamline\u001b[0m\u001b[33m operations\u001b[0m\u001b[33m and\u001b[0m\u001b[33m security\u001b[0m\u001b[33m across\u001b[0m\u001b[33m IT\u001b[0m\u001b[33m environments\u001b[0m\u001b[33m and\u001b[0m\u001b[33m deliver\u001b[0m\u001b[33m greater\u001b[0m\u001b[33m consistency\u001b[0m\u001b[33m to\u001b[0m\u001b[33m all\u001b[0m\u001b[33m applications\u001b[0m\u001b[33m,\u001b[0m\u001b[33m from\u001b[0m\u001b[33m cloud\u001b[0m\u001b[33m-native\u001b[0m\u001b[33m and\u001b[0m\u001b[33m AI\u001b[0m\u001b[33m-enabled\u001b[0m\u001b[33m to\u001b[0m\u001b[33m virtual\u001b[0m\u001b[33mized\u001b[0m\u001b[33m and\u001b[0m\u001b[33m traditional\u001b[0m\u001b[33m.\n",
      ",\n",
      ",\u001b[0m\u001b[33mHere\u001b[0m\u001b[33m's\u001b[0m\u001b[33m a\u001b[0m\u001b[33m draft\u001b[0m\u001b[33m email\u001b[0m\u001b[33m to\u001b[0m\u001b[33m convey\u001b[0m\u001b[33m this\u001b[0m\u001b[33m information\u001b[0m\u001b[33m:\n",
      ",\n",
      ",\u001b[0m\u001b[33mSubject\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Latest\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m Version\u001b[0m\u001b[33m Available\u001b[0m\u001b[33m\n",
      ",\n",
      ",\u001b[0m\u001b[33mDear\u001b[0m\u001b[33m Team\u001b[0m\u001b[33m,\n",
      ",\n",
      ",\u001b[0m\u001b[33mI\u001b[0m\u001b[33m wanted\u001b[0m\u001b[33m to\u001b[0m\u001b[33m let\u001b[0m\u001b[33m you\u001b[0m\u001b[33m know\u001b[0m\u001b[33m that\u001b[0m\u001b[33m the\u001b[0m\u001b[33m latest\u001b[0m\u001b[33m version\u001b[0m\u001b[33m of\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m,\u001b[0m\u001b[33m version\u001b[0m\u001b[33m \u001b[0m\u001b[33m4\u001b[0m\u001b[33m.\u001b[0m\u001b[33m18\u001b[0m\u001b[33m,\u001b[0m\u001b[33m is\u001b[0m\u001b[33m now\u001b[0m\u001b[33m available\u001b[0m\u001b[33m.\u001b[0m\u001b[33m This\u001b[0m\u001b[33m version\u001b[0m\u001b[33m includes\u001b[0m\u001b[33m new\u001b[0m\u001b[33m features\u001b[0m\u001b[33m and\u001b[0m\u001b[33m capabilities\u001b[0m\u001b[33m that\u001b[0m\u001b[33m aim\u001b[0m\u001b[33m to\u001b[0m\u001b[33m improve\u001b[0m\u001b[33m the\u001b[0m\u001b[33m overall\u001b[0m\u001b[33m experience\u001b[0m\u001b[33m of\u001b[0m\u001b[33m using\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m,\u001b[0m\u001b[33m including\u001b[0m\u001b[33m enhanced\u001b[0m\u001b[33m security\u001b[0m\u001b[33m and\u001b[0m\u001b[33m virtual\u001b[0m\u001b[33mization\u001b[0m\u001b[33m options\u001b[0m\u001b[33m.\n",
      ",\n",
      ",\u001b[0m\u001b[33mIf\u001b[0m\u001b[33m you\u001b[0m\u001b[33m're\u001b[0m\u001b[33m interested\u001b[0m\u001b[33m in\u001b[0m\u001b[33m learning\u001b[0m\u001b[33m more\u001b[0m\u001b[33m about\u001b[0m\u001b[33m the\u001b[0m\u001b[33m new\u001b[0m\u001b[33m features\u001b[0m\u001b[33m and\u001b[0m\u001b[33m capabilities\u001b[0m\u001b[33m in\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m \u001b[0m\u001b[33m4\u001b[0m\u001b[33m.\u001b[0m\u001b[33m18\u001b[0m\u001b[33m,\u001b[0m\u001b[33m I\u001b[0m\u001b[33m recommend\u001b[0m\u001b[33m checking\u001b[0m\u001b[33m out\u001b[0m\u001b[33m the\u001b[0m\u001b[33m official\u001b[0m\u001b[33m Red\u001b[0m\u001b[33m Hat\u001b[0m\u001b[33m website\u001b[0m\u001b[33m for\u001b[0m\u001b[33m more\u001b[0m\u001b[33m information\u001b[0m\u001b[33m.\n",
      ",\n",
      ",\u001b[0m\u001b[33mBest\u001b[0m\u001b[33m,\n",
      ",\u001b[0m\u001b[33m[\u001b[0m\u001b[33mYour\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m]\n",
      ",\n",
      ",\u001b[0m\u001b[33mSent\u001b[0m\u001b[33m from\u001b[0m\u001b[33m my\u001b[0m\u001b[33m llama\u001b[0m\u001b[33m-stack\u001b[0m\u001b[33m agent\u001b[0m\u001b[97m\u001b[0m\n",
      ",\u001b[30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "from llama_stack_client.lib.agents.agent import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    instructions=sys_prompt2,\n",
    "    tools=[\"builtin::websearch\", \"mcp::openshift\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params={\n",
    "        \"max_tokens\":4096,\n",
    "        \"strategy\": {\"type\": \"greedy\"},\n",
    "    }\n",
    ")\n",
    "\n",
    "session_id = agent.create_session(session_name=\"Draft_email_with_latest_OCP_version\")\n",
    "\n",
    "prompt_chaining = os.getenv(\"USE_PROMPT_CHAINING\") # Decide if prompt should be destructured into multiple turns or \n",
    "\n",
    "if prompt_chaining and prompt_chaining is True:\n",
    "    prompts = [\n",
    "        \"\"\"Search for the web for the latest Red Hat OpenShift version on the Red Hat website.\"\"\",\n",
    "        \"\"\"Summarize the latest Red Hat OpenShift version number and any significant features, fixes, or changes that occure in this version.\"\"\",\n",
    "        \"\"\"Draft and format an email to convey this information to my team members.\"\"\"\n",
    "    ]\n",
    "    for i, prompt in enumerate(prompts):    \n",
    "        turn_response = agent.create_turn(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            session_id=session_id,\n",
    "            stream=True,\n",
    "        )\n",
    "        logger.info(f\"========= Turn: {i} =========\")\n",
    "        for log in EventLogger().log(turn_response):\n",
    "            log.print()\n",
    "else:\n",
    "    prompt = \"\"\"Search for the web for the latest Red Hat OpenShift version on the Red Hat website. Summarize the version number and draft an email to convey this information.\"\"\"\n",
    "    turn_response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=True,\n",
    "    )\n",
    "    for log in EventLogger().log(turn_response):\n",
    "        log.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81fb87-19cd-4755-96d5-59628cc75daf",
   "metadata": {},
   "source": [
    "#### Output Analysis\n",
    "\n",
    "Lets step through the output to further understands whats happening in this Agentic demo.\n",
    "\n",
    "1. First the LLM sends off a tool call to the `brave_search` to lookup the latest version of Red Hat Openshift.\n",
    "2. The LLM recieves the response from the tool call, results of the search, along with the orrigional query. Each search result has:\n",
    "    - Title of the webpage\n",
    "    - Website URL\n",
    "    - Relevant content exerpt from the search result\n",
    "    - A score, quanitifying how relevant is the search result to the search query\n",
    "    - raw_content from the page\n",
    "3. Finally, this context gets passed back to the LLM for the final inference. The inference result starts my responding to my initial question with some background, and then finally drafting the email that was requested. This example was ran without prompt-chaining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa880bbc-bf69-4777-9417-ef7b13d51785",
   "metadata": {},
   "source": [
    "## Query 3: (MCP) `Summarize any errors that might be happening on my OpenShift Cluster`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa47903-99b2-424d-bd0c-487b011460fc",
   "metadata": {},
   "source": [
    "**Note:** For this query, when using `ibm-granite/granite-3.2-8b-instruct` model for tool calling, we followed the system prompt as per the official IBM documentation:\n",
    "https://www.ibm.com/granite/docs/models/granite/#function-calling and observed that it produced more reliable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210ff58-2fed-498e-91f9-b0dd04d35436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a system prompt we have come up which works well for this query\n",
    "sys_prompt3= \"\"\"You are a helpful AI assistant with access to the tools listed next. When a tool is required to answer the user's query, respond with `<tool_call>` followed by a JSON object of the tool used. For example: `<tool_call> {\"name\":\"function_name\",\"arguments\":{\"arg1\":\"value\"}} </tool_call>`:The user will respond with the output of the tool execution response so you can continue with the rest of the initial user prompt (continue).\n",
    "If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc7957e4-581c-4c3d-aee7-b8e3d9f2d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33minference> \u001b[0m\u001b[33m<\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_\u001b[0m\u001b[33mcall\u001b[0m\u001b[33m>\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:pods_log Args:{'name': 'hello-world', 'namespace': 'llama-serve'}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:pods_log Response:{\"type\":\"text\",\"text\":\"\\nHello from Docker!\\nThis message shows that your installation appears to be working correctly.\\n\\nTo generate this message, Docker took the following steps:\\n 1. The Docker client contacted the Docker daemon.\\n 2. The Docker daemon pulled the \\\"hello-world\\\" image from the Docker Hub.\\n    (amd64)\\n 3. The Docker daemon created a new container from that image which runs the\\n    executable that produces the output you are currently reading.\\n 4. The Docker daemon streamed that output to the Docker client, which sent it\\n    to your terminal.\\n\\nTo try something more ambitious, you can run an Ubuntu container with:\\n $ docker run -it ubuntu bash\\n\\nShare images, automate workflows, and more with a free Docker ID:\\n https://hub.docker.com/\\n\\nFor more examples and ideas, visit:\\n https://docs.docker.com/get-started/\\n\\n\",\"annotations\":null}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33m|\u001b[0m\u001b[33m Pod\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m |\u001b[0m\u001b[33m Category\u001b[0m\u001b[33m |\u001b[0m\u001b[33m Ex\u001b[0m\u001b[33mplanation\u001b[0m\u001b[33m |\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m|------------\u001b[0m\u001b[33m|\u001b[0m\u001b[33m----------|\u001b[0m\u001b[33m-----------\u001b[0m\u001b[33m|\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m|\u001b[0m\u001b[33m hello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m |\u001b[0m\u001b[33m Normal\u001b[0m\u001b[33m |\u001b[0m\u001b[33m The\u001b[0m\u001b[33m log\u001b[0m\u001b[33m output\u001b[0m\u001b[33m indicates\u001b[0m\u001b[33m a\u001b[0m\u001b[33m successful\u001b[0m\u001b[33m execution\u001b[0m\u001b[33m of\u001b[0m\u001b[33m the\u001b[0m\u001b[33m '\u001b[0m\u001b[33mhello\u001b[0m\u001b[33m-\u001b[0m\u001b[33mworld\u001b[0m\u001b[33m'\u001b[0m\u001b[33m Docker\u001b[0m\u001b[33m image\u001b[0m\u001b[33m.\u001b[0m\u001b[33m The\u001b[0m\u001b[33m message\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mHello\u001b[0m\u001b[33m from\u001b[0m\u001b[33m Docker\u001b[0m\u001b[33m!\"\u001b[0m\u001b[33m suggests\u001b[0m\u001b[33m that\u001b[0m\u001b[33m the\u001b[0m\u001b[33m container\u001b[0m\u001b[33m started\u001b[0m\u001b[33m and\u001b[0m\u001b[33m ran\u001b[0m\u001b[33m the\u001b[0m\u001b[33m expected\u001b[0m\u001b[33m command\u001b[0m\u001b[33m without\u001b[0m\u001b[33m any\u001b[0m\u001b[33m errors\u001b[0m\u001b[33m,\u001b[0m\u001b[33m thus\u001b[0m\u001b[33m class\u001b[0m\u001b[33mifying\u001b[0m\u001b[33m it\u001b[0m\u001b[33m as\u001b[0m\u001b[33m a\u001b[0m\u001b[33m normal\u001b[0m\u001b[33m operation\u001b[0m\u001b[33m.\u001b[0m\u001b[33m |\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m\u001b[33minference> \u001b[0m\u001b[33m<\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_\u001b[0m\u001b[33mcall\u001b[0m\u001b[33m>\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:pods_log Args:{'name': 'test-pod', 'namespace': 'llama-serve'}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:pods_log Response:{\"type\":\"text\",\"text\":\"The pod test-pod in namespace llama-serve has not logged any message yet\",\"annotations\":null}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33m|\u001b[0m\u001b[33m Pod\u001b[0m\u001b[33m Name\u001b[0m\u001b[33m |\u001b[0m\u001b[33m Category\u001b[0m\u001b[33m |\u001b[0m\u001b[33m Ex\u001b[0m\u001b[33mplanation\u001b[0m\u001b[33m |\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m|------------\u001b[0m\u001b[33m|\u001b[0m\u001b[33m----------|\u001b[0m\u001b[33m-----------\u001b[0m\u001b[33m|\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m|\u001b[0m\u001b[33m test\u001b[0m\u001b[33m-\u001b[0m\u001b[33mpod\u001b[0m\u001b[33m |\u001b[0m\u001b[33m Normal\u001b[0m\u001b[33m |\u001b[0m\u001b[33m The\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m '\u001b[0m\u001b[33mtest\u001b[0m\u001b[33m-\u001b[0m\u001b[33mpod\u001b[0m\u001b[33m'\u001b[0m\u001b[33m in\u001b[0m\u001b[33m the\u001b[0m\u001b[33m '\u001b[0m\u001b[33mll\u001b[0m\u001b[33mama\u001b[0m\u001b[33m-\u001b[0m\u001b[33mserve\u001b[0m\u001b[33m'\u001b[0m\u001b[33m namespace\u001b[0m\u001b[33m has\u001b[0m\u001b[33m not\u001b[0m\u001b[33m logged\u001b[0m\u001b[33m any\u001b[0m\u001b[33m messages\u001b[0m\u001b[33m yet\u001b[0m\u001b[33m,\u001b[0m\u001b[33m indicating\u001b[0m\u001b[33m that\u001b[0m\u001b[33m it\u001b[0m\u001b[33m has\u001b[0m\u001b[33m not\u001b[0m\u001b[33m started\u001b[0m\u001b[33m or\u001b[0m\u001b[33m has\u001b[0m\u001b[33m been\u001b[0m\u001b[33m recently\u001b[0m\u001b[33m stopped\u001b[0m\u001b[33m.\u001b[0m\u001b[33m This\u001b[0m\u001b[33m is\u001b[0m\u001b[33m class\u001b[0m\u001b[33mified\u001b[0m\u001b[33m as\u001b[0m\u001b[33m '\u001b[0m\u001b[33mNormal\u001b[0m\u001b[33m'\u001b[0m\u001b[33m because\u001b[0m\u001b[33m it\u001b[0m\u001b[33m's\u001b[0m\u001b[33m expected\u001b[0m\u001b[33m behavior\u001b[0m\u001b[33m for\u001b[0m\u001b[33m a\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m that\u001b[0m\u001b[33m hasn\u001b[0m\u001b[33m't\u001b[0m\u001b[33m been\u001b[0m\u001b[33m actively\u001b[0m\u001b[33m running\u001b[0m\u001b[33m to\u001b[0m\u001b[33m not\u001b[0m\u001b[33m have\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m.\u001b[0m\u001b[33m |\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "from llama_stack_client import Agent\n",
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=granite_model, # replace this with your choice of model\n",
    "    instructions = sys_prompt3 , # update system prompt based on the model you are using\n",
    "    tools=[\"mcp::openshift\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params={\"max_tokens\":4096}\n",
    ")\n",
    "\n",
    "user_prompts = [\"View the logs for pod 'hello-world' in the llama-serve namespace. Categorize it as 'Normal' or 'Error'. You must strictly answer with the pod name and category normal or error in a table format and also briefly explain why you categorized it as normal or error.\",\n",
    "               \"View the logs for pod 'test-pod' in the llama-serve namespace. Categorize it as 'Normal' or 'Error'. You must strictly answer with the pod name and category normal or error in a table format and also briefly explain why you categorized it as normal or error.\"]\n",
    "session_id = agent.create_session(session_name=\"OCP_demo\")\n",
    "\n",
    "for prompt in user_prompts:\n",
    "    turn_response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=True,\n",
    "    )\n",
    "    for log in EventLogger().log(turn_response):\n",
    "        log.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323a025-b836-41f4-bd05-27c92d577640",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Lets step through the output to further understands whats happening in this Agentic demo.\n",
    "\n",
    "1. First the LLM sends off a tool call to the pods_log tool configured with the OpenShift MCP server, to fetch the logs for the pod specified from the OpenShift cluster.\n",
    "2. The tool successfully retrieves the logs for the pod.\n",
    "3. The LLM recieves the response from the tool call, which are the pod logs, along with the original query.\n",
    "4. Finally, this context gets passed back to the LLM for the final inference. The inference result provides the final answer in a structured table format as requested in the user prompt and provides the pod name, its category of 'Normal' or 'Error' along with a brief explanantion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbc8ab-77c6-48ff-970c-2d5dfd54a2c7",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "This tutorial demonstrates how to build agentic MCP applications with Llama Stack. We do so by initializing an agent while giving it access to the MCP tools configured with Llama Stack, then invoking the agent on each of the specified queries. Please check out our other notebooks for more examples using Llama Stack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
